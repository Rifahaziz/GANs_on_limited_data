{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fca0c1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T00:07:09.764234Z",
     "iopub.status.busy": "2021-12-04T00:07:09.763899Z",
     "iopub.status.idle": "2021-12-04T00:07:11.683336Z",
     "shell.execute_reply": "2021-12-04T00:07:11.682528Z",
     "shell.execute_reply.started": "2021-12-04T00:07:09.764167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GANTransferLimitedData'...\n",
      "remote: Enumerating objects: 211, done.\u001b[K\n",
      "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
      "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
      "remote: Total 211 (delta 38), reused 3 (delta 0), pack-reused 141\u001b[K\n",
      "Receiving objects: 100% (211/211), 8.66 MiB | 13.02 MiB/s, done.\n",
      "Resolving deltas: 100% (106/106), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MiaoyunZhao/GANTransferLimitedData.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96eadfab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T19:59:35.349138Z",
     "iopub.status.busy": "2021-12-04T19:59:35.348873Z",
     "iopub.status.idle": "2021-12-04T19:59:35.357145Z",
     "shell.execute_reply": "2021-12-04T19:59:35.356641Z",
     "shell.execute_reply.started": "2021-12-04T19:59:35.349084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/git-repos/GANTransferLimitedData\n"
     ]
    }
   ],
   "source": [
    "cd GANTransferLimitedData/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614d83c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T19:59:38.017462Z",
     "iopub.status.busy": "2021-12-04T19:59:38.017177Z",
     "iopub.status.idle": "2021-12-04T20:00:12.085455Z",
     "shell.execute_reply": "2021-12-04T20:00:12.084870Z",
     "shell.execute_reply.started": "2021-12-04T19:59:38.017438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/git-repos/GANTransferLimitedData/gan_training/config.py:18: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg_special = yaml.load(f)\n",
      "/home/jovyan/git-repos/GANTransferLimitedData/gan_training/config.py:29: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(f)\n",
      "Generator(\n",
      "  (embedding): Embedding(1000, 256)\n",
      "  (fc): Linear(in_features=512, out_features=16384, bias=True)\n",
      "  (resnet_0_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_0_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_1_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_1_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_2_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_s): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (resnet_2_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_3_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_s): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (resnet_3_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_4_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_s): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (resnet_4_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_5_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_s): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (resnet_5_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conv_img): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Discriminator(\n",
      "  (conv_img): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (resnet_0_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_0_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_s): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (resnet_1_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_1_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_s): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (resnet_2_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_2_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_s): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (resnet_3_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_3_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_s): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (resnet_4_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_4_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_5_0): ResnetBlock(\n",
      "    (conv_0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resnet_5_1): ResnetBlock(\n",
      "    (conv_0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv_1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (fc): Linear(in_features=16384, out_features=1000, bias=True)\n",
      ")\n",
      "tensor([[ 0.0039,  0.0093,  0.0101],\n",
      "        [ 0.0077, -0.0061,  0.0070],\n",
      "        [ 0.0059,  0.0023,  0.0077]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "https://s3.eu-central-1.amazonaws.com/avg-projects/gan_stability/models/imagenet-8c505f47.pt\n",
      "=> Loading checkpoint from url...\n",
      "tensor([[ 0.1460,  0.0110, -0.0497],\n",
      "        [ 0.0074,  0.0181, -0.0525],\n",
      "        [ 0.0588, -0.0327,  0.0424]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "!python download_pretrainedGAN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ae9d9ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T00:23:49.604556Z",
     "iopub.status.busy": "2021-12-04T00:23:49.603988Z",
     "iopub.status.idle": "2021-12-04T00:23:49.612086Z",
     "shell.execute_reply": "2021-12-04T00:23:49.611265Z",
     "shell.execute_reply.started": "2021-12-04T00:23:49.604527Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '__Version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_166/368891291.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__Version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute '__Version__'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__Version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09dc24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T20:00:12.087185Z",
     "iopub.status.busy": "2021-12-04T20:00:12.086839Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/git-repos/GANTransferLimitedData/gan_training/config.py:18: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg_special = yaml.load(f)\n",
      "/home/jovyan/git-repos/GANTransferLimitedData/gan_training/config.py:29: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlabels ============  1\n",
      "Total= 27963332 Trainable= 23056897 fixed= 4906435\n",
      "Start training...\n",
      "Total= 27963332 Trainable= 23056897 fixed= 4906435\n",
      "Total= 91892161 Trainable= 37769217 fixed= 54122944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0, it    0] g_loss = 0.6946, d_loss = 1.3862, reg=0.0000, d_fix=-0.0469, d_update=-0.0026, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 100, it  100] g_loss = 0.5241, d_loss = 1.4212, reg=0.0291, d_fix=-0.0469, d_update=-0.0028, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 200, it  200] g_loss = 1.3422, d_loss = 1.0962, reg=0.0320, d_fix=-0.0469, d_update=-0.0023, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 300, it  300] g_loss = 0.7901, d_loss = 0.9376, reg=0.0438, d_fix=-0.0469, d_update=-0.0025, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 400, it  400] g_loss = 1.2786, d_loss = 0.7604, reg=0.0672, d_fix=-0.0469, d_update=-0.0027, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 500, it  500] g_loss = 1.7485, d_loss = 0.7805, reg=0.0907, d_fix=-0.0469, d_update=-0.0027, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 600, it  600] g_loss = 1.5327, d_loss = 0.5703, reg=0.0805, d_fix=-0.0469, d_update=-0.0028, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 700, it  700] g_loss = 1.1511, d_loss = 0.6038, reg=0.1007, d_fix=-0.0469, d_update=-0.0029, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 800, it  800] g_loss = 1.7612, d_loss = 0.5886, reg=0.0795, d_fix=-0.0469, d_update=-0.0028, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 900, it  900] g_loss = 1.9089, d_loss = 0.6882, reg=0.0931, d_fix=-0.0469, d_update=-0.0028, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 1000, it 1000] g_loss = 1.0660, d_loss = 0.6749, reg=0.0864, d_fix=-0.0469, d_update=-0.0029, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 1100, it 1100] g_loss = 1.5876, d_loss = 0.6501, reg=0.0782, d_fix=-0.0469, d_update=-0.0029, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 1200, it 1200] g_loss = 1.7196, d_loss = 0.6368, reg=0.0703, d_fix=-0.0469, d_update=-0.0029, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 1300, it 1300] g_loss = 1.5808, d_loss = 0.6801, reg=0.0710, d_fix=-0.0469, d_update=-0.0028, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 1400, it 1400] g_loss = 1.4059, d_loss = 0.7140, reg=0.0821, d_fix=-0.0469, d_update=-0.0028, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 1500, it 1500] g_loss = 1.8655, d_loss = 0.8086, reg=0.0851, d_fix=-0.0469, d_update=-0.0027, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 1600, it 1600] g_loss = 1.0285, d_loss = 0.7433, reg=0.0807, d_fix=-0.0469, d_update=-0.0027, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 1700, it 1700] g_loss = 1.9549, d_loss = 0.5801, reg=0.0714, d_fix=-0.0469, d_update=-0.0026, g_fix=-0.0001, g_update=0.0000\n",
      "[epoch 1800, it 1800] g_loss = 0.8900, d_loss = 0.8937, reg=0.0797, d_fix=-0.0469, d_update=-0.0025, g_fix=-0.0001, g_update=0.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "import os, sys\n",
    "from os import path\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import random\n",
    "# from torchsummary import summary\n",
    "import shutil\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(999)\n",
    "\n",
    "\n",
    "from gan_training import utils\n",
    "from gan_training.train import Trainer, update_average\n",
    "from gan_training.toggle_ImageNet import toggle_grad_G, toggle_grad_D\n",
    "from gan_training.logger import Logger\n",
    "from gan_training.checkpoints import CheckpointIO\n",
    "from gan_training.inputs import get_dataset\n",
    "from gan_training.distributions import get_ydist, get_zdist\n",
    "from gan_training.eval import Evaluator\n",
    "from gan_training.config import (\n",
    "    load_config, build_models, build_optimizers, build_lr_scheduler, build_models_PRE,\n",
    ")\n",
    "\n",
    "\n",
    "def my_embedding(z, y, nlabels=1):\n",
    "    e_y=torch.zeros(y.shape[0], nlabels,device=y.device).scatter_(1, (y).unsqueeze(1), 1)\n",
    "    # print('e_y.shape===============', e_y.shape)\n",
    "    output = z * e_y\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_parameter_number(net):\n",
    "    total_num = sum(p.numel() for p in net.parameters())\n",
    "    trainable_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    print('Total=', total_num, 'Trainable=', trainable_num, 'fixed=', total_num-trainable_num)\n",
    "\n",
    "\n",
    "def load_part_model(m_fix, m_ini):\n",
    "    dict_fix = m_fix.state_dic()\n",
    "    dict_ini = m_ini.state_dic()\n",
    "\n",
    "    dict_fix = {k: v for k, v in dict_fix.items() if k in dict_ini and k.find('embedding')==-1 and k.find('fc') == -1}\n",
    "    dict_ini.update(dict_fix)\n",
    "    m_ini.load_state_dict(dict_ini)\n",
    "    return m_ini\n",
    "\n",
    "\n",
    "def model_equal_all(model, dict):\n",
    "    model_dict = model.state_dict()\n",
    "    model_dict.update(dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_equal_part(model, dict_all):\n",
    "    model_dict = model.state_dict()\n",
    "    dict_fix = {k: v for k, v in dict_all.items() if k in model_dict and k.find('embedding') == -1 and k.find('fc') == -1}\n",
    "    model_dict.update(dict_fix)\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "''' ===================--- Set the traning mode ---==========================\n",
    "DATA: going to train\n",
    "DATA_FIX: used as a fixed pre-trained model\n",
    "G_Layer_FIX, D_Layer_FIX: number of layers to fix\n",
    "============================================================================='''\n",
    "DATA_FIX = 'ImageNet'\n",
    "Num_epoch = 5000 *10000\n",
    "method = 'AdaFM' # scratch\n",
    "\n",
    "main_path = './'\n",
    "load_dir = './pretrained_model/'\n",
    "\n",
    "\n",
    "DATA = 'textures'\n",
    "image_path = 'data/originals/'\n",
    "test_path = 'data/originals/'\n",
    "\n",
    "\n",
    "out_path = main_path+'/'+DATA+'_our_contral_kernel_25_v2_16z_10reg/'\n",
    "config_path = 'configs/' +DATA+ '.yaml'\n",
    "\n",
    "\n",
    "for choose in range(1):\n",
    "\n",
    "    G_Layer_FIX = -4\n",
    "    D_Layer_FIX = 6\n",
    "\n",
    "    config = load_config(config_path, 'configs/default.yaml')\n",
    "\n",
    "    config['generator']['layers'] = G_Layer_FIX\n",
    "    config['discriminator']['layers'] = D_Layer_FIX\n",
    "    config['data']['train_dir'] = image_path\n",
    "    config['data']['test_dir'] = test_path\n",
    "    config['z_dist']['dim'] = 4\n",
    "    config['training']['reg_type'] = 'real_fake'\n",
    "    config['training']['reg_param'] = 20.0\n",
    "    config['training']['batch_size'] = 16\n",
    "\n",
    "    config['generator']['name'] = 'resnet2_AdaFM'\n",
    "    config['discriminator']['name'] = 'resnet2_AdaFM'\n",
    "\n",
    "    config['training']['out_dir'] = out_path + 'G_%d_D_%d/'%(-G_Layer_FIX, D_Layer_FIX)\n",
    "    if not os.path.isdir(config['training']['out_dir']):\n",
    "        os.makedirs(config['training']['out_dir'])\n",
    "\n",
    "    if 1:\n",
    "        # Short hands\n",
    "        batch_size = config['training']['batch_size']\n",
    "        d_steps = config['training']['d_steps']\n",
    "        restart_every = config['training']['restart_every']\n",
    "        inception_every = config['training']['inception_every']\n",
    "        save_every = config['training']['save_every']\n",
    "        backup_every = config['training']['backup_every']\n",
    "        sample_nlabels = config['training']['sample_nlabels']\n",
    "\n",
    "        out_dir = config['training']['out_dir']\n",
    "        checkpoint_dir = path.join(out_dir, 'chkpts')\n",
    "\n",
    "        # Create missing directories\n",
    "        if not path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        if not path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        shutil.copyfile(sys.argv[0], out_dir + '/training_script.py')\n",
    "\n",
    "        # Logger\n",
    "        checkpoint_io = CheckpointIO(\n",
    "            checkpoint_dir=checkpoint_dir\n",
    "        )\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Dataset\n",
    "        train_dataset, nlabels = get_dataset(\n",
    "            name=config['data']['type'],\n",
    "            data_dir=config['data']['train_dir'],\n",
    "            size=config['data']['img_size'],\n",
    "            lsun_categories=config['data']['lsun_categories_train']\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                num_workers=config['training']['nworkers'],\n",
    "                shuffle=True, pin_memory=True, sampler=None, drop_last=True\n",
    "        )\n",
    "        test_dataset, nlabels = get_dataset(\n",
    "            name=config['data']['type'],\n",
    "            data_dir=config['data']['test_dir'],\n",
    "            size=config['data']['img_size'],\n",
    "            lsun_categories=config['data']['lsun_categories_train']\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=config['training']['nworkers'],\n",
    "            shuffle=True, pin_memory=True, sampler=None, drop_last=True\n",
    "        )\n",
    "\n",
    "        # Number of labels\n",
    "        nlabels = min(nlabels, config['data']['nlabels'])\n",
    "        sample_nlabels = min(nlabels, sample_nlabels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Create models\n",
    "        ''' --------- Choose the fixed layer ---------------'''\n",
    "        generator, discriminator = build_models(config)\n",
    "\n",
    "        if method == 'AdaFM':\n",
    "            dict_G = torch.load(load_dir + DATA_FIX + 'Pre_generator')\n",
    "            generator = model_equal_part(generator, dict_G)\n",
    "            dict_D = torch.load(load_dir + DATA_FIX + 'Pre_discriminator')\n",
    "            discriminator = model_equal_part(discriminator, dict_D)\n",
    "\n",
    "            for name, param in generator.named_parameters():\n",
    "                if name.find('small') >= 0:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "                if name.find('small_adafm_') >= 0:\n",
    "                    param.requires_grad = False\n",
    "            get_parameter_number(generator)\n",
    "\n",
    "            for param in discriminator.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            #toggle_grad_G(generator, True, G_Layer_FIX)\n",
    "            toggle_grad_D(discriminator, True, D_Layer_FIX)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Put models on gpu if needed\n",
    "        generator, discriminator = generator.to(device), discriminator.to(device)\n",
    "        g_optimizer, d_optimizer = build_optimizers(generator, discriminator, config)\n",
    "\n",
    "\n",
    "        # Register modules to checkpoint\n",
    "        checkpoint_io.register_modules(\n",
    "            generator=generator,\n",
    "            discriminator=discriminator,\n",
    "            g_optimizer=g_optimizer,\n",
    "            d_optimizer=d_optimizer,\n",
    "        )\n",
    "\n",
    "\n",
    "        # Logger\n",
    "        logger = Logger(\n",
    "            log_dir=path.join(out_dir, 'logs'),\n",
    "            img_dir=path.join(out_dir, 'imgs'),\n",
    "            monitoring=config['training']['monitoring'],\n",
    "            monitoring_dir=path.join(out_dir, 'monitoring')\n",
    "        )\n",
    "\n",
    "        # Distributions\n",
    "        ydist = get_ydist(1, device=device)\n",
    "        zdist = get_zdist(config['z_dist']['type'], config['z_dist']['dim'],\n",
    "                          device=device)\n",
    "\n",
    "        # Save for tests\n",
    "        ntest = 16\n",
    "        x_real, ytest = utils.get_nsamples(train_loader, ntest)\n",
    "        ytest.clamp_(None, nlabels-1)\n",
    "        ytest = ytest.to(device)\n",
    "        ztest = zdist.sample((ntest,)).to(device)\n",
    "        # utils.save_images(x_real, path.join(out_dir, 'real.png'))\n",
    "\n",
    "        # Test generator\n",
    "        if config['training']['take_model_average']:\n",
    "            generator_test = copy.deepcopy(generator)\n",
    "            checkpoint_io.register_modules(generator_test=generator_test)\n",
    "        else:\n",
    "            generator_test = generator\n",
    "\n",
    "        # Evaluator\n",
    "\n",
    "        NNN = 251\n",
    "        x_real, _ = utils.get_nsamples(test_loader, NNN)\n",
    "        evaluator = Evaluator(generator_test, zdist, ydist,\n",
    "                              batch_size=batch_size, device=device,\n",
    "                              fid_real_samples=x_real, inception_nsamples=NNN, fid_sample_size=NNN)\n",
    "        # Train\n",
    "        tstart = t0 = time.time()\n",
    "\n",
    "\n",
    "        it = -1\n",
    "        epoch_idx = -1\n",
    "\n",
    "        # Reinitialize model average if needed\n",
    "        if (config['training']['take_model_average']\n",
    "                and config['training']['model_average_reinit']):\n",
    "            update_average(generator_test, generator, 0.)\n",
    "\n",
    "        # Learning rate anneling\n",
    "        g_scheduler = build_lr_scheduler(g_optimizer, config, last_epoch=it)\n",
    "        d_scheduler = build_lr_scheduler(d_optimizer, config, last_epoch=it)\n",
    "\n",
    "        # Trainer\n",
    "        trainer = Trainer(\n",
    "            generator, discriminator, g_optimizer, d_optimizer,\n",
    "            gan_type=config['training']['gan_type'],\n",
    "            reg_type=config['training']['reg_type'],\n",
    "            reg_param=config['training']['reg_param'],\n",
    "            D_fix_layer=config['discriminator']['layers']\n",
    "        )\n",
    "\n",
    "\n",
    "    # Training loop\n",
    "    print('Start training...')\n",
    "    save_dir = config['training']['out_dir'] + '/models/'\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    FLAG = 500\n",
    "\n",
    "    inception_mean_all = []\n",
    "    inception_std_all = []\n",
    "    fid_all = []\n",
    "    get_parameter_number(generator)\n",
    "    get_parameter_number(discriminator)\n",
    "\n",
    "    for epoch_idx in range(Num_epoch):\n",
    "\n",
    "        for x_real, y in train_loader:\n",
    "            it += 1\n",
    "            g_scheduler.step()\n",
    "            d_scheduler.step()\n",
    "\n",
    "            d_lr = d_optimizer.param_groups[0]['lr']\n",
    "            g_lr = g_optimizer.param_groups[0]['lr']\n",
    "\n",
    "            x_real, y = x_real.to(device), y.to(device)\n",
    "            y.clamp_(None, nlabels-1)\n",
    "\n",
    "            # Generators updates\n",
    "            z = zdist.sample((batch_size,)).to(device)\n",
    "\n",
    "            gloss, x_fake = trainer.generator_trainstep(y, z, FLAG + 1.0)\n",
    "            FLAG = FLAG * 0.9995\n",
    "\n",
    "            if config['training']['take_model_average']:\n",
    "                update_average(generator_test, generator,\n",
    "                               beta=config['training']['model_average_beta'])\n",
    "\n",
    "            # Discriminator updates\n",
    "            dloss, reg = trainer.discriminator_trainstep(x_real, y, x_fake)\n",
    "\n",
    "            if method == 'AdaFM' and it == 10000:\n",
    "                for name, param in generator.named_parameters():\n",
    "                    if name.find('small_adafm_') >= 0:\n",
    "                        param.requires_grad = True\n",
    "                get_parameter_number(generator)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # (i) Sample if necessary\n",
    "                if (it % 100) == 0:\n",
    "                    d_fix, d_update = discriminator.conv_img.weight[1, 1, 1, 1], discriminator.fc.weight[0, 1]\n",
    "                    g_fix, g_update = generator.conv_img.weight[1, 1, 1, 1], 0.0\n",
    "\n",
    "                    print('[epoch %0d, it %4d] g_loss = %.4f, d_loss = %.4f, reg=%.4f, d_fix=%.4f, d_update=%.4f, g_fix=%.4f, g_update=%.4f'\n",
    "                          % (epoch_idx, it, gloss, dloss, reg, d_fix, d_update, g_fix, g_update))\n",
    "                    # print('Creating samples...')\n",
    "                    x, _ = generator_test(ztest, ytest)\n",
    "                    logger.add_imgs(x, 'all', it, nrow=10)\n",
    "\n",
    "                # (ii) Compute inception if necessary\n",
    "                if ((it + 2) % 5000) == 0:\n",
    "                    inception_mean, inception_std, fid = evaluator.compute_inception_score()\n",
    "                    inception_mean_all.append(inception_mean)\n",
    "                    inception_std_all.append(inception_std)\n",
    "                    fid_all.append(fid)\n",
    "                    print('test it %d: IS: mean %.2f, std %.2f, FID: mean %.2f, time: %2f' % (\n",
    "                        it, inception_mean, inception_std, fid, time.time() - tstart))\n",
    "\n",
    "                    FID = np.stack(fid_all)\n",
    "                    Inception_mean = np.stack(inception_mean_all)\n",
    "                    Inception_std = np.stack(inception_std_all)\n",
    "                    sio.savemat(out_path + DATA + 'base_FID_IS.mat', {'FID': FID,\n",
    "                                                           'Inception_mean': Inception_mean,\n",
    "                                                           'Inception_std': Inception_std})\n",
    "\n",
    "                # (iii) Backup if necessary\n",
    "                if ((it + 1) % backup_every) == 0:\n",
    "                    print('Saving backup...')\n",
    "                    checkpoint_io.save('model_%08d.pt' % it, it=it)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccb967f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T00:32:07.799742Z",
     "iopub.status.busy": "2021-12-04T00:32:07.799449Z",
     "iopub.status.idle": "2021-12-04T00:32:08.582568Z",
     "shell.execute_reply": "2021-12-04T00:32:08.581994Z",
     "shell.execute_reply.started": "2021-12-04T00:32:07.799717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CELEBA_[f]GmDn.py'\t     gan_training\n",
      " configs\t\t     LICENSE\n",
      " data\t\t\t     pretrained_model\n",
      " download_pretrainedGAN.py   README.md\n",
      " F:\t\t\t     textures_our_contral_kernel_25_v2_16z_10reg\n",
      "'Flower_[h]our.py'\t     TransferGANLimitedData_v4.pdf\n",
      " Flowers25_our.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180e5022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T17:11:37.854133Z",
     "iopub.status.busy": "2021-12-04T17:11:37.853793Z",
     "iopub.status.idle": "2021-12-04T17:11:37.930635Z",
     "shell.execute_reply": "2021-12-04T17:11:37.929636Z",
     "shell.execute_reply.started": "2021-12-04T17:11:37.854060Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19271/3682325369.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fid' is not defined"
     ]
    }
   ],
   "source": [
    "fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd14a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
