{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4c7c74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T01:53:27.531721Z",
     "iopub.status.busy": "2021-11-30T01:53:27.531490Z",
     "iopub.status.idle": "2021-11-30T01:53:27.536277Z",
     "shell.execute_reply": "2021-11-30T01:53:27.535742Z",
     "shell.execute_reply.started": "2021-11-30T01:53:27.531697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/git-repos/stylegan2-ada-pytorch\n"
     ]
    }
   ],
   "source": [
    "cd stylegan2-ada-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3658d38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T01:53:31.292676Z",
     "iopub.status.busy": "2021-11-30T01:53:31.292455Z",
     "iopub.status.idle": "2021-11-30T01:53:42.852731Z",
     "shell.execute_reply": "2021-11-30T01:53:42.852125Z",
     "shell.execute_reply.started": "2021-11-30T01:53:31.292654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [00:10<00:00, 18.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "!python dataset_tool.py --source=textures/resizedandaugmented966/ --dest=data966_256.zip \\\n",
    "    --width=256 --height=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a11d62a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T02:02:50.200144Z",
     "iopub.status.busy": "2021-11-30T02:02:50.199891Z",
     "iopub.status.idle": "2021-11-30T02:03:17.266330Z",
     "shell.execute_reply": "2021-11-30T02:03:17.265657Z",
     "shell.execute_reply.started": "2021-11-30T02:02:50.200116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/brecahad.pkl\"...\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/brecahad.pkl ... done\n",
      "Generating W vectors...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Generating images...\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "Generating style-mixed images...\n",
      "Saving images...\n",
      "Saving image grid...\n"
     ]
    }
   ],
   "source": [
    "!python style_mixing.py --outdir=out --rows=85,100,75,458,1500 --cols=55,821,1789,293 \\\n",
    "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/brecahad.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0460eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T02:11:31.763536Z",
     "iopub.status.busy": "2021-11-30T02:11:31.763293Z",
     "iopub.status.idle": "2021-11-30T02:11:33.783740Z",
     "shell.execute_reply": "2021-11-30T02:11:33.783119Z",
     "shell.execute_reply.started": "2021-11-30T02:11:31.763509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 50,\n",
      "  \"network_snapshot_ticks\": 50,\n",
      "  \"metrics\": [\n",
      "    \"fid50k_full\"\n",
      "  ],\n",
      "  \"random_seed\": 0,\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"data966_256.zip\",\n",
      "    \"use_labels\": false,\n",
      "    \"max_size\": 191,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 256\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"num_workers\": 3,\n",
      "    \"prefetch_factor\": 2\n",
      "  },\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 2\n",
      "    },\n",
      "    \"synthesis_kwargs\": {\n",
      "      \"channel_base\": 16384,\n",
      "      \"channel_max\": 512,\n",
      "      \"num_fp16_res\": 4,\n",
      "      \"conv_clamp\": 256\n",
      "    }\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Discriminator\",\n",
      "    \"block_kwargs\": {},\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 16384,\n",
      "    \"channel_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 0.8192\n",
      "  },\n",
      "  \"total_kimg\": 1000,\n",
      "  \"batch_size\": 16,\n",
      "  \"batch_gpu\": 16,\n",
      "  \"ema_kimg\": 5.0,\n",
      "  \"ema_rampup\": 0.05,\n",
      "  \"ada_target\": 0.6,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"run_dir\": \"~/training-runs/00001-data966_256-auto1\"\n",
      "}\n",
      "\n",
      "Output directory:   ~/training-runs/00001-data966_256-auto1\n",
      "Training data:      data966_256.zip\n",
      "Training duration:  1000 kimg\n",
      "Number of GPUs:     1\n",
      "Number of images:   191\n",
      "Image resolution:   256\n",
      "Conditional model:  False\n",
      "Dataset x-flips:    False\n",
      "\n",
      "Dry run; exiting.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --outdir=~/training-runs --data=data966_256.zip --gpus=1 --dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c278feef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T02:10:28.557569Z",
     "iopub.status.busy": "2021-11-30T02:10:28.557345Z",
     "iopub.status.idle": "2021-11-30T02:10:30.515547Z",
     "shell.execute_reply": "2021-11-30T02:10:30.514952Z",
     "shell.execute_reply.started": "2021-11-30T02:10:28.557545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: train.py [OPTIONS]\n",
      "\n",
      "  Train a GAN using the techniques described in the paper \"Training\n",
      "  Generative Adversarial Networks with Limited Data\".\n",
      "\n",
      "  Examples:\n",
      "\n",
      "  # Train with custom dataset using 1 GPU.\n",
      "  python train.py --outdir=~/training-runs --data=~/mydataset.zip --gpus=1\n",
      "\n",
      "  # Train class-conditional CIFAR-10 using 2 GPUs.\n",
      "  python train.py --outdir=~/training-runs --data=~/datasets/cifar10.zip \\\n",
      "      --gpus=2 --cfg=cifar --cond=1\n",
      "\n",
      "  # Transfer learn MetFaces from FFHQ using 4 GPUs.\n",
      "  python train.py --outdir=~/training-runs --data=~/datasets/metfaces.zip \\\n",
      "      --gpus=4 --cfg=paper1024 --mirror=1 --resume=ffhq1024 --snap=10\n",
      "\n",
      "  # Reproduce original StyleGAN2 config F.\n",
      "  python train.py --outdir=~/training-runs --data=~/datasets/ffhq.zip \\\n",
      "      --gpus=8 --cfg=stylegan2 --mirror=1 --aug=noaug\n",
      "\n",
      "  Base configs (--cfg):\n",
      "    auto       Automatically select reasonable defaults based on resolution\n",
      "               and GPU count. Good starting point for new datasets.\n",
      "    stylegan2  Reproduce results for StyleGAN2 config F at 1024x1024.\n",
      "    paper256   Reproduce results for FFHQ and LSUN Cat at 256x256.\n",
      "    paper512   Reproduce results for BreCaHAD and AFHQ at 512x512.\n",
      "    paper1024  Reproduce results for MetFaces at 1024x1024.\n",
      "    cifar      Reproduce results for CIFAR-10 at 32x32.\n",
      "\n",
      "  Transfer learning source networks (--resume):\n",
      "    ffhq256        FFHQ trained at 256x256 resolution.\n",
      "    ffhq512        FFHQ trained at 512x512 resolution.\n",
      "    ffhq1024       FFHQ trained at 1024x1024 resolution.\n",
      "    celebahq256    CelebA-HQ trained at 256x256 resolution.\n",
      "    lsundog256     LSUN Dog trained at 256x256 resolution.\n",
      "    <PATH or URL>  Custom network pickle.\n",
      "\n",
      "Options:\n",
      "  --outdir DIR                    Where to save the results  [required]\n",
      "  --gpus INT                      Number of GPUs to use [default: 1]\n",
      "  --snap INT                      Snapshot interval [default: 50 ticks]\n",
      "  --metrics LIST                  Comma-separated list or \"none\" [default:\n",
      "                                  fid50k_full]\n",
      "\n",
      "  --seed INT                      Random seed [default: 0]\n",
      "  -n, --dry-run                   Print training options and exit\n",
      "  --data PATH                     Training data (directory or zip)  [required]\n",
      "  --cond BOOL                     Train conditional model based on dataset\n",
      "                                  labels [default: false]\n",
      "\n",
      "  --subset INT                    Train with only N images [default: all]\n",
      "  --mirror BOOL                   Enable dataset x-flips [default: false]\n",
      "  --cfg [auto|stylegan2|paper256|paper512|paper1024|cifar]\n",
      "                                  Base config [default: auto]\n",
      "  --gamma FLOAT                   Override R1 gamma\n",
      "  --kimg INT                      Override training duration\n",
      "  --batch INT                     Override batch size\n",
      "  --aug [noaug|ada|fixed]         Augmentation mode [default: ada]\n",
      "  --p FLOAT                       Augmentation probability for --aug=fixed\n",
      "  --target FLOAT                  ADA target value for --aug=ada\n",
      "  --augpipe [blit|geom|color|filter|noise|cutout|bg|bgc|bgcf|bgcfn|bgcfnc]\n",
      "                                  Augmentation pipeline [default: bgc]\n",
      "  --resume PKL                    Resume training [default: noresume]\n",
      "  --freezed INT                   Freeze-D [default: 0 layers]\n",
      "  --fp32 BOOL                     Disable mixed-precision training\n",
      "  --nhwc BOOL                     Use NHWC memory format with FP16\n",
      "  --nobench BOOL                  Disable cuDNN benchmarking\n",
      "  --allow-tf32 BOOL               Allow PyTorch to use TF32 internally\n",
      "  --workers INT                   Override number of DataLoader workers\n",
      "  --help                          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be856f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T02:12:57.678795Z",
     "iopub.status.busy": "2021-11-30T02:12:57.678486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 50,\n",
      "  \"network_snapshot_ticks\": 50,\n",
      "  \"metrics\": [\n",
      "    \"fid50k_full\"\n",
      "  ],\n",
      "  \"random_seed\": 0,\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"data966_256.zip\",\n",
      "    \"use_labels\": false,\n",
      "    \"max_size\": 191,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 256\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"num_workers\": 3,\n",
      "    \"prefetch_factor\": 2\n",
      "  },\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 2\n",
      "    },\n",
      "    \"synthesis_kwargs\": {\n",
      "      \"channel_base\": 16384,\n",
      "      \"channel_max\": 512,\n",
      "      \"num_fp16_res\": 4,\n",
      "      \"conv_clamp\": 256\n",
      "    }\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Discriminator\",\n",
      "    \"block_kwargs\": {},\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 16384,\n",
      "    \"channel_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 0.8192\n",
      "  },\n",
      "  \"total_kimg\": 1000,\n",
      "  \"batch_size\": 16,\n",
      "  \"batch_gpu\": 16,\n",
      "  \"ema_kimg\": 5.0,\n",
      "  \"ema_rampup\": 0.05,\n",
      "  \"ada_target\": 0.6,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"run_dir\": \"~/training-runs2/00000-data966_256-auto1\"\n",
      "}\n",
      "\n",
      "Output directory:   ~/training-runs2/00000-data966_256-auto1\n",
      "Training data:      data966_256.zip\n",
      "Training duration:  1000 kimg\n",
      "Number of GPUs:     1\n",
      "Number of images:   191\n",
      "Image resolution:   256\n",
      "Conditional model:  False\n",
      "Dataset x-flips:    False\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "\n",
      "Num images:  191\n",
      "Image shape: [3, 256, 256]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "\n",
      "Generator             Parameters  Buffers  Output shape         Datatype\n",
      "---                   ---         ---      ---                  ---     \n",
      "mapping.fc0           262656      -        [16, 512]            float32 \n",
      "mapping.fc1           262656      -        [16, 512]            float32 \n",
      "mapping               -           512      [16, 14, 512]        float32 \n",
      "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
      "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
      "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
      "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
      "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
      "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
      "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
      "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
      "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
      "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
      "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
      "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
      "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
      "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
      "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
      "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
      "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
      "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
      "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
      "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
      "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
      "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
      "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
      "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
      "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
      "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
      "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
      "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
      "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
      "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
      "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
      "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
      "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
      "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
      "---                   ---         ---      ---                  ---     \n",
      "Total                 23191522    175568   -                    -       \n",
      "\n",
      "\n",
      "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
      "---            ---         ---      ---                  ---     \n",
      "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
      "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
      "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
      "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
      "b256           -           16       [16, 128, 128, 128]  float16 \n",
      "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
      "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
      "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
      "b128           -           16       [16, 256, 64, 64]    float16 \n",
      "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
      "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
      "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
      "b64            -           16       [16, 512, 32, 32]    float16 \n",
      "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
      "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
      "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
      "b32            -           16       [16, 512, 16, 16]    float16 \n",
      "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
      "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
      "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
      "b16            -           16       [16, 512, 8, 8]      float32 \n",
      "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
      "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
      "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
      "b8             -           16       [16, 512, 4, 4]      float32 \n",
      "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
      "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
      "b4.fc          4194816     -        [16, 512]            float32 \n",
      "b4.out         513         -        [16, 1]              float32 \n",
      "---            ---         ---      ---                  ---     \n",
      "Total          24001089    416      -                    -       \n",
      "\n",
      "Setting up augmentation...\n",
      "Distributing across 1 GPUs...\n",
      "Setting up training phases...\n",
      "Exporting sample images...\n",
      "Initializing logs...\n",
      "Training for 1000 kimg...\n",
      "\n",
      "tick 0     kimg 0.0      time 41s          sec/tick 7.2     sec/kimg 447.43  maintenance 34.3   cpumem 3.15   gpumem 10.38  augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 347.88562061205266}, \"metric\": \"fid50k_full\", \"total_time\": 600.6781311035156, \"total_time_str\": \"10m 01s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1638239035.9682977}\n",
      "tick 1     kimg 4.0      time 15m 25s      sec/tick 268.6   sec/kimg 67.15   maintenance 615.1  cpumem 3.69   gpumem 5.32   augment 0.007\n",
      "tick 2     kimg 8.0      time 19m 44s      sec/tick 258.4   sec/kimg 64.60   maintenance 0.1    cpumem 3.69   gpumem 4.91   augment 0.013\n",
      "tick 3     kimg 12.0     time 23m 59s      sec/tick 254.9   sec/kimg 63.72   maintenance 0.1    cpumem 3.69   gpumem 4.91   augment 0.018\n",
      "tick 4     kimg 16.0     time 28m 20s      sec/tick 261.6   sec/kimg 65.39   maintenance 0.1    cpumem 3.69   gpumem 4.91   augment 0.023\n",
      "tick 5     kimg 20.0     time 32m 51s      sec/tick 270.7   sec/kimg 67.69   maintenance 0.1    cpumem 3.69   gpumem 4.91   augment 0.029\n",
      "tick 6     kimg 24.0     time 37m 21s      sec/tick 269.4   sec/kimg 67.35   maintenance 0.1    cpumem 3.69   gpumem 4.94   augment 0.036\n",
      "tick 7     kimg 28.0     time 41m 37s      sec/tick 256.2   sec/kimg 64.06   maintenance 0.1    cpumem 3.69   gpumem 4.91   augment 0.043\n",
      "tick 8     kimg 32.0     time 46m 08s      sec/tick 271.2   sec/kimg 67.79   maintenance 0.1    cpumem 3.70   gpumem 4.91   augment 0.049\n",
      "tick 9     kimg 36.0     time 50m 39s      sec/tick 270.8   sec/kimg 67.70   maintenance 0.1    cpumem 3.70   gpumem 4.91   augment 0.056\n",
      "tick 10    kimg 40.0     time 55m 00s      sec/tick 260.5   sec/kimg 65.12   maintenance 0.1    cpumem 3.70   gpumem 4.94   augment 0.063\n",
      "tick 11    kimg 44.0     time 59m 17s      sec/tick 256.8   sec/kimg 64.19   maintenance 0.1    cpumem 3.70   gpumem 4.91   augment 0.071\n",
      "tick 12    kimg 48.0     time 1h 03m 35s   sec/tick 257.9   sec/kimg 64.47   maintenance 0.1    cpumem 3.70   gpumem 4.91   augment 0.077\n",
      "tick 13    kimg 52.0     time 1h 07m 53s   sec/tick 257.6   sec/kimg 64.41   maintenance 0.1    cpumem 3.70   gpumem 4.91   augment 0.084\n",
      "tick 14    kimg 56.0     time 1h 12m 11s   sec/tick 258.4   sec/kimg 64.60   maintenance 0.1    cpumem 3.70   gpumem 4.93   augment 0.090\n",
      "tick 15    kimg 60.0     time 1h 16m 44s   sec/tick 272.8   sec/kimg 68.21   maintenance 0.1    cpumem 3.70   gpumem 4.92   augment 0.097\n",
      "tick 16    kimg 64.0     time 1h 21m 17s   sec/tick 272.9   sec/kimg 68.22   maintenance 0.1    cpumem 3.70   gpumem 4.94   augment 0.103\n",
      "tick 17    kimg 68.0     time 1h 25m 49s   sec/tick 271.9   sec/kimg 67.97   maintenance 0.1    cpumem 3.70   gpumem 4.94   augment 0.109\n",
      "tick 18    kimg 72.0     time 1h 30m 09s   sec/tick 260.0   sec/kimg 65.00   maintenance 0.1    cpumem 3.70   gpumem 4.92   augment 0.117\n",
      "tick 19    kimg 76.0     time 1h 34m 27s   sec/tick 257.1   sec/kimg 64.27   maintenance 0.1    cpumem 3.70   gpumem 4.96   augment 0.121\n",
      "tick 20    kimg 80.0     time 1h 38m 51s   sec/tick 264.8   sec/kimg 66.21   maintenance 0.1    cpumem 3.70   gpumem 4.94   augment 0.129\n",
      "tick 21    kimg 84.0     time 1h 43m 19s   sec/tick 267.5   sec/kimg 66.87   maintenance 0.1    cpumem 3.70   gpumem 4.93   augment 0.135\n",
      "tick 22    kimg 88.0     time 1h 47m 37s   sec/tick 257.7   sec/kimg 64.42   maintenance 0.1    cpumem 3.70   gpumem 4.95   augment 0.140\n",
      "tick 23    kimg 92.0     time 1h 51m 54s   sec/tick 257.2   sec/kimg 64.31   maintenance 0.1    cpumem 3.70   gpumem 4.92   augment 0.147\n",
      "tick 24    kimg 96.0     time 1h 56m 28s   sec/tick 273.4   sec/kimg 68.35   maintenance 0.1    cpumem 3.70   gpumem 4.94   augment 0.154\n",
      "tick 25    kimg 100.0    time 2h 00m 46s   sec/tick 257.7   sec/kimg 64.42   maintenance 0.1    cpumem 3.70   gpumem 4.95   augment 0.161\n",
      "tick 26    kimg 104.0    time 2h 05m 03s   sec/tick 257.6   sec/kimg 64.40   maintenance 0.1    cpumem 3.70   gpumem 5.00   augment 0.168\n",
      "tick 27    kimg 108.0    time 2h 09m 21s   sec/tick 257.4   sec/kimg 64.35   maintenance 0.1    cpumem 3.71   gpumem 4.99   augment 0.173\n",
      "tick 28    kimg 112.0    time 2h 13m 39s   sec/tick 258.1   sec/kimg 64.52   maintenance 0.1    cpumem 3.71   gpumem 4.95   augment 0.179\n",
      "tick 29    kimg 116.0    time 2h 18m 01s   sec/tick 261.7   sec/kimg 65.42   maintenance 0.1    cpumem 3.71   gpumem 4.93   augment 0.186\n",
      "tick 30    kimg 120.0    time 2h 22m 32s   sec/tick 270.8   sec/kimg 67.71   maintenance 0.1    cpumem 3.71   gpumem 4.95   augment 0.194\n",
      "tick 31    kimg 124.0    time 2h 26m 50s   sec/tick 257.6   sec/kimg 64.39   maintenance 0.1    cpumem 3.71   gpumem 4.96   augment 0.200\n",
      "tick 32    kimg 128.0    time 2h 31m 22s   sec/tick 272.6   sec/kimg 68.15   maintenance 0.1    cpumem 3.71   gpumem 4.97   augment 0.206\n",
      "tick 33    kimg 132.0    time 2h 35m 40s   sec/tick 257.7   sec/kimg 64.43   maintenance 0.1    cpumem 3.71   gpumem 4.94   augment 0.212\n",
      "tick 34    kimg 136.0    time 2h 40m 10s   sec/tick 270.0   sec/kimg 67.50   maintenance 0.1    cpumem 3.71   gpumem 4.96   augment 0.218\n",
      "tick 35    kimg 140.0    time 2h 44m 32s   sec/tick 261.3   sec/kimg 65.33   maintenance 0.1    cpumem 3.71   gpumem 4.95   augment 0.225\n",
      "tick 36    kimg 144.0    time 2h 48m 50s   sec/tick 258.3   sec/kimg 64.58   maintenance 0.1    cpumem 3.71   gpumem 4.97   augment 0.232\n",
      "tick 37    kimg 148.0    time 2h 53m 13s   sec/tick 262.7   sec/kimg 65.68   maintenance 0.1    cpumem 3.71   gpumem 5.01   augment 0.238\n",
      "tick 38    kimg 152.0    time 2h 57m 43s   sec/tick 269.7   sec/kimg 67.43   maintenance 0.1    cpumem 3.71   gpumem 4.96   augment 0.244\n",
      "tick 39    kimg 156.0    time 3h 02m 01s   sec/tick 257.9   sec/kimg 64.49   maintenance 0.1    cpumem 3.71   gpumem 4.94   augment 0.251\n",
      "tick 40    kimg 160.0    time 3h 06m 18s   sec/tick 257.2   sec/kimg 64.29   maintenance 0.1    cpumem 3.71   gpumem 4.98   augment 0.257\n",
      "tick 41    kimg 164.0    time 3h 10m 35s   sec/tick 256.7   sec/kimg 64.19   maintenance 0.1    cpumem 3.71   gpumem 4.99   augment 0.265\n",
      "tick 42    kimg 168.0    time 3h 14m 54s   sec/tick 258.4   sec/kimg 64.59   maintenance 0.1    cpumem 3.71   gpumem 4.98   augment 0.271\n",
      "tick 43    kimg 172.0    time 3h 19m 12s   sec/tick 257.8   sec/kimg 64.46   maintenance 0.1    cpumem 3.71   gpumem 4.99   augment 0.276\n",
      "tick 44    kimg 176.0    time 3h 23m 30s   sec/tick 258.7   sec/kimg 64.67   maintenance 0.1    cpumem 3.71   gpumem 4.99   augment 0.284\n",
      "tick 45    kimg 180.0    time 3h 27m 52s   sec/tick 261.6   sec/kimg 65.40   maintenance 0.1    cpumem 3.71   gpumem 4.98   augment 0.291\n",
      "tick 46    kimg 184.0    time 3h 32m 26s   sec/tick 273.3   sec/kimg 68.32   maintenance 0.1    cpumem 3.71   gpumem 5.00   augment 0.297\n",
      "tick 47    kimg 188.0    time 3h 36m 58s   sec/tick 272.6   sec/kimg 68.15   maintenance 0.1    cpumem 3.72   gpumem 4.98   augment 0.304\n",
      "tick 48    kimg 192.0    time 3h 41m 16s   sec/tick 258.0   sec/kimg 64.49   maintenance 0.1    cpumem 3.72   gpumem 4.97   augment 0.310\n",
      "tick 49    kimg 196.0    time 3h 45m 48s   sec/tick 271.9   sec/kimg 67.97   maintenance 0.1    cpumem 3.72   gpumem 4.99   augment 0.318\n",
      "tick 50    kimg 200.0    time 3h 50m 22s   sec/tick 273.9   sec/kimg 68.48   maintenance 0.1    cpumem 3.72   gpumem 4.97   augment 0.324\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 173.68142010481037}, \"metric\": \"fid50k_full\", \"total_time\": 581.6682510375977, \"total_time_str\": \"9m 42s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000200.pkl\", \"timestamp\": 1638252801.3918965}\n",
      "tick 51    kimg 204.0    time 4h 04m 55s   sec/tick 273.0   sec/kimg 68.26   maintenance 599.5  cpumem 3.72   gpumem 4.99   augment 0.330\n",
      "tick 52    kimg 208.0    time 4h 09m 29s   sec/tick 273.5   sec/kimg 68.37   maintenance 0.1    cpumem 3.72   gpumem 4.99   augment 0.337\n",
      "tick 53    kimg 212.0    time 4h 14m 02s   sec/tick 273.4   sec/kimg 68.36   maintenance 0.1    cpumem 3.72   gpumem 5.01   augment 0.343\n",
      "tick 54    kimg 216.0    time 4h 18m 36s   sec/tick 273.4   sec/kimg 68.35   maintenance 0.1    cpumem 3.72   gpumem 4.98   augment 0.348\n",
      "tick 55    kimg 220.0    time 4h 23m 10s   sec/tick 273.7   sec/kimg 68.42   maintenance 0.1    cpumem 3.72   gpumem 5.03   augment 0.353\n",
      "tick 56    kimg 224.0    time 4h 27m 41s   sec/tick 271.7   sec/kimg 67.93   maintenance 0.1    cpumem 3.72   gpumem 5.01   augment 0.360\n",
      "tick 57    kimg 228.0    time 4h 32m 00s   sec/tick 258.6   sec/kimg 64.65   maintenance 0.1    cpumem 3.72   gpumem 5.01   augment 0.365\n",
      "tick 58    kimg 232.0    time 4h 36m 19s   sec/tick 258.2   sec/kimg 64.56   maintenance 0.1    cpumem 3.72   gpumem 4.98   augment 0.369\n",
      "tick 59    kimg 236.0    time 4h 40m 51s   sec/tick 272.2   sec/kimg 68.04   maintenance 0.1    cpumem 3.72   gpumem 4.99   augment 0.374\n",
      "tick 60    kimg 240.0    time 4h 45m 12s   sec/tick 261.4   sec/kimg 65.35   maintenance 0.1    cpumem 3.72   gpumem 4.99   augment 0.379\n",
      "tick 61    kimg 244.0    time 4h 49m 42s   sec/tick 269.5   sec/kimg 67.38   maintenance 0.1    cpumem 3.72   gpumem 5.01   augment 0.385\n",
      "tick 62    kimg 248.0    time 4h 54m 16s   sec/tick 273.7   sec/kimg 68.43   maintenance 0.1    cpumem 3.73   gpumem 4.99   augment 0.390\n",
      "tick 63    kimg 252.0    time 4h 58m 50s   sec/tick 273.8   sec/kimg 68.46   maintenance 0.1    cpumem 3.73   gpumem 5.01   augment 0.395\n",
      "tick 64    kimg 256.0    time 5h 03m 19s   sec/tick 268.8   sec/kimg 67.21   maintenance 0.1    cpumem 3.73   gpumem 5.04   augment 0.401\n",
      "tick 65    kimg 260.0    time 5h 07m 40s   sec/tick 261.4   sec/kimg 65.35   maintenance 0.1    cpumem 3.73   gpumem 4.97   augment 0.404\n",
      "tick 66    kimg 264.0    time 5h 12m 14s   sec/tick 273.7   sec/kimg 68.41   maintenance 0.1    cpumem 3.73   gpumem 5.00   augment 0.410\n",
      "tick 67    kimg 268.0    time 5h 16m 32s   sec/tick 258.1   sec/kimg 64.53   maintenance 0.1    cpumem 3.73   gpumem 4.97   augment 0.414\n",
      "tick 68    kimg 272.0    time 5h 21m 07s   sec/tick 274.7   sec/kimg 68.68   maintenance 0.1    cpumem 3.73   gpumem 5.01   augment 0.420\n",
      "tick 69    kimg 276.0    time 5h 25m 42s   sec/tick 274.4   sec/kimg 68.61   maintenance 0.1    cpumem 3.73   gpumem 4.99   augment 0.425\n",
      "tick 70    kimg 280.0    time 5h 30m 16s   sec/tick 274.5   sec/kimg 68.63   maintenance 0.1    cpumem 3.73   gpumem 4.98   augment 0.429\n",
      "tick 71    kimg 284.0    time 5h 34m 40s   sec/tick 263.5   sec/kimg 65.87   maintenance 0.1    cpumem 3.73   gpumem 5.01   augment 0.434\n",
      "tick 72    kimg 288.0    time 5h 39m 00s   sec/tick 259.9   sec/kimg 64.96   maintenance 0.1    cpumem 3.73   gpumem 5.01   augment 0.438\n",
      "tick 73    kimg 292.0    time 5h 43m 25s   sec/tick 264.8   sec/kimg 66.20   maintenance 0.1    cpumem 3.73   gpumem 4.99   augment 0.443\n"
     ]
    }
   ],
   "source": [
    "!python train.py --outdir=~/training-runs2 --data=data966_256.zip --gpus=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904dd9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
